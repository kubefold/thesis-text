\chapter{Zagadnienie teoretyczne}


\section{Problem przewidywania konformacji białek}
Przewidywanie konformacji białek to kluczowy problem biologii obliczeniowej~\cite{alphafold3}, który polega na określeniu trójwymiarowej struktury białka na podstawie sekwencji aminokwasów.
Struktura przestrzenna białka bezpośrednio wpływa na jego funkcję biologiczną, a dokładne przewidywanie konformacji pozwala zrozumieć mechanizmy działania białek oraz projektować nowe leki.
Jest to zadanie trudne ze względu na ogromną liczbę możliwych konformacji oraz złożone oddziaływania między atomami.
Problem ten staje się szczególnie istotny dla białek, których struktury nie udało się wyznaczyć metodami eksperymentalnymi ze względu na trudności techniczne.
Zastosowanie przewidywanych struktur w medycynie spersonalizowanej oraz farmacji stanowi jeden z najbardziej obiecujących kierunków rozwoju współczesnej biotechnologii.

\subsection{Kodowanie trójwymiarowej struktury białka}
Aminokwasy w łańcuchu polipeptydowym kodują strukturę przestrzenną białka poprzez swoją sekwencję i właściwości fizykochemiczne.
Każdy aminokwas ma specyficzne cechy, takie jak hydrofobowość, ładunek elektryczny czy wielkość, które determinują możliwe oddziaływania i ułożenie w przestrzeni~\cite{protein_folding}.
Sposób ułożenia aminokwasów w przestrzeni jest zapisany w tak zwanym kodzie konformacyjnym, który opisuje różne poziomy organizacji struktury białka.

Strukturę przestrzenną białka opisuje się na kilku hierarchicznych poziomach organizacji:

\begin{itemize}
    \item Struktura pierwszorzędowa-liniowa sekwencja aminokwasów połączonych wiązaniami peptydowymi, która zawiera pełną informację niezbędną do uformowania struktury natywnej
    \item Struktura drugorzędowa-lokalne motywy strukturalne powstające dzięki wiązaniom wodorowym między grupami peptydowymi, takie jak helisy alfa i harmonijki beta
    \item Struktura trzeciorzędowa-globalne ułożenie całego łańcucha polipeptydowego stabilizowane różnymi oddziaływaniami między aminokwasami
    \item Struktura czwartorzędowa-sposób asocjacji kilku łańcuchów polipeptydowych w funkcjonalny kompleks białkowy
\end{itemize}

\subsection{Krystalografia rentgenowska}
Krystalografia rentgenowska to podstawowa metoda doświadczalna określania struktury białek~\cite{xray_crystallography}, która polega na analizie dyfrakcji promieni rentgenowskich na krysztale białka.
Promienie rentgenowskie rozpraszają się na elektronach atomów tworzących białko, a wzór dyfrakcyjny jest rejestrowany i analizowany matematycznie.
Na tej podstawie tworzy się mapa gęstości elektronowej, której analiza wymaga zastosowania złożonych algorytmów matematycznych i wiedzy z zakresu krystalografii.
Interpretacja map gęstości elektronowej stanowi wyzwanie wymagające często ręcznego dopasowania modelu białka przez doświadczonych badaczy.

Proces krystalizacji białka jest często najtrudniejszym etapem, wymagającym znacznych nakładów finansowych i zaawansowanej infrastruktury laboratoryjnej.

\subsection{Komputerowe metody obliczania konformacji białka}
Metody komputerowe przewidywania struktury białek dzielą się na kilka głównych kategorii, wśród których metody oparte na homologii wykorzystują podobieństwo sekwencji do białek o znanej strukturze.
Metody ab initio próbują przewidywać strukturę wyłącznie na podstawie sekwencji i praw fizyki~\cite{ab_initio_protein_folding}, podczas gdy metody fold recognition dopasowują sekwencję do znanych motywów strukturalnych.
Każda z tych metod ma swoje ograniczenia i najlepiej sprawdza się w określonych warunkach, zależnie od dostępności danych referencyjnych.
Hybrydy tych metod często dają lepsze wyniki niż pojedyncze podejścia, łącząc zalety różnych technik przewidywania.

Tradycyjne podejścia obliczeniowe obejmują symulacje dynamiki molekularnej i metody Monte Carlo, które wykorzystują pola siłowe opisujące oddziaływania między atomami.
Obliczenia te są bardzo kosztowne obliczeniowo i często ograniczone do małych białek, jednak w ostatnich latach metody uczenia maszynowego i głębokiego odniosły znaczący sukces w tym obszarze.
Postęp w sprzęcie obliczeniowym, szczególnie w obszarze akceleratorów GPU i specjalizowanych procesorów tensorowych, znacząco przyspieszył obliczenia struktur białkowych.
Rozwój infrastruktury chmurowej umożliwił demokratyzację dostępu do zaawansowanych narzędzi bioinformatycznych.

Przełomem w dziedzinie było opracowanie algorytmu AlphaFold przez firmę Google DeepMind, który wykorzystuje sieci neuronowe do przewidywania struktury białek z dokładnością porównywalną do metod eksperymentalnych.
AlphaFold2 zrewolucjonizował dziedzinę, wygrywając konkurs CASP14~\cite{casp} (Critical Assessment of protein Structure Prediction) w 2020 roku~\cite{alphafold2}.
Metody oparte na uczeniu głębokim znacząco przyspieszyły tempo odkryć naukowych w biologii strukturalnej, a publiczne udostępnienie modelu AlphaFold umożliwiło badaczom na całym świecie wykorzystanie tej technologii w projektach badawczych i medycznych.
Integracja wyników AlphaFold z innymi technikami bioinformatycznymi otworzyła nowe możliwości w analizie interakcji białko-białko i projektowaniu leków.
Najnowsza wersja algorytmu-AlphaFold 3 - osiąga dokładność przewidywania struktury białek na poziomie 90--95\% w przypadku pojedynczych łańcuchów polipeptydowych, a dla kompleksów białkowych dokładność sięga 80--85\%, co stanowi znaczący postęp w porównaniu do poprzednich wersji~\cite{alphafold3}.

\section{Algorytm AlphaFold firmy Google Deepmind}

\subsection{Informacje wstępne}

\subsection{Implementacja algorytmu}

\subsection{Omówienie działania programu}

\subsection{Wymagane zasoby obliczeniowe}


\section{Obliczenia w klastrze obliczeniowym}

\subsection{Platforma Kubernetes}

Kubernetes to otwarte oprogramowanie do orkiestracji kontenerów, które automatyzuje wdrażanie, skalowanie i zarządzanie aplikacjami~\cite{kubernetes}.
Jest obecnie głównym rozwiązaniem w obszarze zarządzania klastrami obliczeniowymi.
Kubernetes wywodzi się z wewnętrznego projektu Google o nazwie Borg, który został udostępniony jako projekt open-source w 2014 roku.

Głównym celem Kubernetes jest zapewnienie platformy do uruchamiania aplikacji w środowisku rozproszonym.
System umożliwia automatyczne zarządzanie zasobami obliczeniowymi w heterogenicznym środowisku sprzętowym, obejmującym różne architektury procesorów oraz dedykowane akceleratory obliczeniowe.
Kubernetes eliminuje wiele ręcznych procesów związanych z wdrażaniem i skalowaniem aplikacji kontenerowych.
Wszystkie komponenty klastra są kontrolowane deklaratywnie.

Architektura Kubernetes opiera się na modelu węzeł główny-węzeł roboczy (z ang. \textit{master-worker}).
Główny komponent kontrolny (z ang. \textit{control plane}) zarządza węzłami roboczymi, na których uruchamiane są faktyczne aplikacje w kontenerach.
Każdy klaster Kubernetes składa się z co najmniej jednego węzła głównego i wielu węzłów roboczych.
Ta architektura zapewnia wysoką dostępność i odporność na awarie.

Model zasobów w Kubernetes jest deklaratywny.
Pod (z ang. \textit{Pod}) jest podstawową jednostką wdrożeniową w Kubernetes, reprezentującą jeden lub więcej kontenerów, które współdzielą zasoby i są zawsze uruchamiane na tym samym węźle klastra.
Po załadowaniu pliku konfiguracyjnego w formacie YAML, Kubernetes będzie dążył do doprowadzenia stanu faktycznego klastra do stanu zadeklarowanego w konfiguracji.
Przykład deklaracji zasobu Wdrożenie (z ang. \textit{Deployment}) przedstawiony w listingu~\ref{lst:kube-deployment} zawiera komentarze objaśniające kluczowe elementy:

\begin{lstlisting}[language=yaml,caption={Przykładowa deklaracja wdrożenia w Kubernetes},label={lst:kube-deployment}]
apiVersion: apps/v1
# Typ zasobu Kubernetes
kind: Deployment 
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  # Liczba replik (kopii) podu do uruchomienia
  replicas: 3
  # Selektor określający które pody należą do wdrożenia
  selector:
    matchLabels:
      app: nginx
  # Szablon definiujący specyfikację podów
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      # Definicja kontenera do uruchomienia
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80  # Port nasłuchiwania w kontenerze
\end{lstlisting}

Kubernetes wprowadza abstrakcję warstwy infrastruktury.
Dzięki temu aplikacje mogą być przenoszone między różnymi dostawcami chmury bez konieczności modyfikacji kodu.
Platforma wspiera różne środowiska uruchomieniowe, od lokalnych klastrów, przez chmury prywatne, aż po głównych dostawców chmury publicznej.

Kluczowe możliwości Kubernetes obejmują:
\begin{itemize}
    \item Automatyczne przywracanie aplikacji w przypadku awarii
    \item Równoważenie obciążenia i dystrybucję ruchu sieciowego
    \item Automatyczne skalowanie poziome aplikacji w zależności od obciążenia
    \item Zarządzanie konfiguracją i sekretami
    \item Zarządzanie trwałym magazynem danych
    \item Batch execution dla zadań wsadowych i harmonogramowanie obliczeń
\end{itemize}

Kubernetes został zaprojektowany jako platforma rozszerzalna.
Pozwala na tworzenie własnych kontrolerów i operatorów dostosowanych do specyficznych potrzeb.
Ta możliwość rozszerzania jest kluczowa dla projektu KubeFold, który wykorzystuje te mechanizmy do orkiestracji złożonych zadań przewidywania konformacji białek.

\subsection{Architektura i komponenty klastra Kubernetes}

Klaster Kubernetes składa się z dwóch głównych części: węzła kontrolnego (\textit{Control Plane}) oraz węzłów roboczych.
Węzeł kontrolny zawiera komponenty zarządzające całym klastrem oraz przechowujące jego stan.

Na węźle kontrolnym działają kluczowe komponenty: \textit{API Server}, będący punktem dostępowym do klastra, \textit{Scheduler} odpowiedzialny za przydzielanie zadań węzłom oraz \textit{Controller Manager} nadzorujący stan klastra.
Za przechowywanie stanu klastra odpowiada baza \textit{etcd}.

Węzły robocze uruchamiają właściwe obciążenia w postaci kontenerów.
Na każdym węźle działa \textit{kubelet} zarządzający kontenerami oraz \textit{kube-proxy} obsługujący ruch sieciowy.
Kontenery grupowane są w \textit{Pod}y stanowiące podstawową jednostkę wdrożeniową.

Kubernetes definiuje abstrakcje wyższego poziomu jak \textit{Deployment} czy \textit{StatefulSet}.
Umożliwiają one deklaratywne zarządzanie aplikacjami. \textit{Service} zapewnia stały punkt dostępowy do grupy \textit{Pod}ów.

Klaster wykorzystuje system pluginów do rozszerzania funkcjonalności.
Obejmuje to sterowniki magazynu, sieci czy monitorowania.
Szczególnie istotne są \textit{Custom Resource Definition} pozwalające na dodawanie własnych typów zasobów.

Architektura Kubernetes zapewnia wysoką dostępność, skalowalność oraz odporność na awarie.
Komponenty mogą być duplikowane między węzłami.
System automatycznie reaguje na awarie poprzez restart i przenoszenie aplikacji.


\subsection{Dostępne zasoby w klastrze obliczeniowym}
Platforma Kubernetes definiuje podstawowe typy zasobów służące do zarządzania aplikacjami w klastrze obliczeniowym.
Każdy typ zasobu pełni określoną rolę i może być konfigurowany przez administratorów oraz aplikacje.

\subsubsection{Pod}
Pod jest podstawową jednostką wdrożeniową w klastrze Kubernetes. 
Reprezentuje on proces wykonujący aplikację wraz z jej kontekstem wykonawczym.
Pod zawiera jeden lub więcej kontenerów współdzielących przestrzeń sieciową oraz zasoby pamięci masowej.
Listing~\ref{lst:pod-example} przedstawia przykładową definicję \textit{Pod}a z serwerem aplikacji i podpiętym wolumenem danych.

\begin{lstlisting}[language=yaml,caption={Przykładowa definicja Pod},label={lst:pod-example}]
apiVersion: v1
kind: Pod
metadata:
  name: web-server
  labels:
    app: web
spec:
  containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    volumeMounts:
    - name: www-data
      mountPath: /usr/share/nginx/html
  volumes:
  - name: www-data
    persistentVolumeClaim:
      claimName: web-content
\end{lstlisting}

\subsubsection{Job}
\textit{Job} reprezentuje zadanie obliczeniowe o skończonym czasie wykonania. 
Zasób ten gwarantuje pomyślne wykonanie zadanej liczby \textit{Pod}ów.
W przypadku awarii węzła obliczeniowego, \textit{Job} automatycznie tworzy nową instancję \textit{Pod}a.
Listing~\ref{lst:job-example} pokazuje przykład \textit{Job}a wykonującego masową konwersję plików.

\begin{lstlisting}[language=yaml,caption={Przykładowa definicja Job},label={lst:job-example}]
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-convert
spec:
  template:
    spec:
      containers:
      - name: converter
        image: imagemagick:latest
        command: ["convert"]
        args: ["*.jpg", "-resize", "800x600", "output/"]
      restartPolicy: Never
  backoffLimit: 4
\end{lstlisting}

\subsubsection{PersistentVolume}
\textit{PersistentVolume} definiuje trwały wolumen pamięci masowej w klastrze.
Jest on niezależny od cyklu życia \textit{Pod}ów i przechowuje dane, które muszą przetrwać restart klastra.
Listing~\ref{lst:pv-example} pokazuje definicję wolumenu wykorzystującego system plików NFS.

\begin{lstlisting}[language=yaml,caption={Przykładowa definicja PersistentVolume},label={lst:pv-example}]
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-volume
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    server: nfs-server.example.com
    path: "/shared"
\end{lstlisting}

\subsubsection{PersistentVolumeClaim}
\textit{PersistentVolumeClaim} jest żądaniem przydzielenia zasobu pamięci masowej.
Definiuje wymagania dotyczące rozmiaru i trybu dostępu do wolumenu.
Listing~\ref{lst:pvc-example} przedstawia przykładowe żądanie utworzenia wolumenu o pojemności 10GB.

\begin{lstlisting}[language=yaml,caption={Przykładowa definicja PersistentVolumeClaim},label={lst:pvc-example}]
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: web-content
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
\end{lstlisting}

\subsubsection{StorageClass}
\textit{StorageClass} opisuje klasę pamięci masowej dostępną w klastrze.
Definiuje ona dostawcę oraz parametry konfiguracyjne dla wolumenów.
Listing~\ref{lst:sc-example} pokazuje definicję standardowej klasy pamięci masowej dla dysków SSD.

\begin{lstlisting}[language=yaml,caption={Przykładowa definicja StorageClass},label={lst:sc-example}]
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-storage
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iopsPerGB: "5000"
  encrypted: "true"
reclaimPolicy: Delete
allowVolumeExpansion: true
\end{lstlisting}

\subsection{Mechanizm przydzielania wolumenów}
Kubernetes wykorzystuje złożony mechanizm do dynamicznego przydzielania zasobów pamięci masowej.
Gdy aplikacja tworzy \textit{PersistentVolumeClaim}, system sprawdza zadeklarowaną w nim klasę pamięci masowej (\textit{StorageClass}).
Na tej podstawie aktywuje odpowiedni sterownik, który tworzy fizyczny wolumen w infrastrukturze.
Nowo utworzony \textit{PersistentVolume} jest następnie automatycznie powiązany z żądaniem.
Dzięki temu mechanizmowi administrator klastra może zdefiniować różne klasy pamięci masowej, a użytkownicy mogą z nich korzystać bez znajomości szczegółów technicznych infrastruktury.
System gwarantuje, że wolumen będzie istniał tak długo, jak istnieje powiązane z nim żądanie.
Po usunięciu \textit{PersistentVolumeClaim}, los wolumenu zależy od zdefiniowanej polityki odzyskiwania - może zostać automatycznie usunięty lub zachowany do ponownego użycia.

\subsection{Klastry Kubernetes w chmurze}

Klastry Kubernetes w środowisku chmurowym stanowią naturalną ewolucję platform obliczeniowych.
Chmura oferuje dynamiczną alokację zasobów oraz integrację z usługami takimi jak magazyny danych czy systemy monitoringu.
Rozproszenie geograficzne zapewnia wysoką dostępność, a mechanizmy automatycznych kopii zapasowych chronią przed utratą danych.
Zaawansowane systemy kontroli dostępu gwarantują bezpieczeństwo danych i aplikacji.

Dostawcy chmury publicznej oferują zarządzane usługi Kubernetes, które automatyzują większość zadań administracyjnych.
Obejmuje to tworzenie i konfigurację klastra, aktualizacje komponentów oraz monitorowanie stanu infrastruktury.
Dzięki temu zespoły mogą skupić się na rozwoju aplikacji zamiast na utrzymaniu infrastruktury.

\subsection{Zarządzana usługa Kubernetes w Amazon Web Services}

Amazon Elastic Kubernetes Service (EKS) stanowi kompleksowe rozwiązanie do uruchamiania klastrów Kubernetes w chmurze AWS.
Usługa automatycznie zarządza aktualizacjami węzłów sterujących, certyfikatami oraz konfiguracją sieci.
Integracja z usługami AWS upraszcza tworzenie rozwiązań wykorzystujących magazyny danych czy systemy powiadomień.

W kontekście projektu KubeFold kluczowe znaczenie ma dostęp do instancji wyposażonych w karty graficzne oraz integracja z systemem plików FSx for Lustre.
EKS umożliwia automatyczne skalowanie grupy węzłów w zależności od zapotrzebowania, co przekłada się na optymalizację kosztów.

Wykorzystanie klastrów Kubernetes w chmurze niesie znaczące korzyści dla projektów obliczeniowych.
Eliminacja kosztów utrzymania własnej infrastruktury oraz dostęp do specjalistycznego sprzętu bez konieczności zakupu pozwalają na elastyczne gospodarowanie budżetem.
Model rozliczania według faktycznego zużycia zasobów sprawdza się szczególnie w przypadku obliczeń o zmiennej intensywności, takich jak przewidywanie konformacji białek.
Automatyczne mechanizmy odtwarzania po awarii oraz globalna dostępność zapewniają niezawodność i wysoką jakość usług.
Ta kombinacja cech sprawia, że chmurowe klastry Kubernetes stanowią optymalne środowisko dla nowoczesnych aplikacji naukowych.

\subsection{Wolumeny Lustre}

Lustre jest rozproszonym systemem plików, stworzonym przez firmę Cluster File Systems w 2003 roku.
System ten został zaprojektowany z myślą o klastrach obliczeniowych wysokiej wydajności.
Obecnie rozwojem Lustre zajmuje się organizacja OpenSFS (Open Scalable File Systems).

System plików Lustre składa się z kilku głównych komponentów:
\begin{itemize}
    \item Serwery metadanych (MDS) - przechowują informacje o strukturze systemu plików, katalogach i uprawnieniach
    \item Serwery obiektów (OSS) - odpowiadają za przechowywanie faktycznych danych i obsługę operacji wejścia/wyjścia
    \item Klienci - węzły, które montują system plików i korzystają z niego
    \item Docelowe urządzenia metadanych (MDT) - przechowują metadane na urządzeniach blokowych
    \item Docelowe urządzenia obiektów (OST) - przechowują dane plików na urządzeniach blokowych
\end{itemize}

Architektura Lustre opiera się na rozdzieleniu metadanych od danych właściwych.
Serwery metadanych zajmują się wyłącznie obsługą operacji na strukturze katalogów i uprawnieniach.
Serwery obiektów obsługują operacje na samych danych plików.
Takie rozdzielenie pozwala na optymalizację obu typów operacji niezależnie.

Lustre zapewnia bardzo wysoką wydajność poprzez równoległe operacje wejścia/wyjścia.
System umożliwia jednoczesny dostęp do tych samych plików z wielu węzłów klastra.
Pojedynczy system plików Lustre może obsługiwać dziesiątki tysięcy klientów jednocześnie.
Przepustowość systemu skaluje się liniowo wraz z dodawaniem kolejnych serwerów obiektów.

Główne cechy systemu plików Lustre:
\begin{itemize}
    \item Wysoka skalowalność - możliwość obsługi petabajtów danych i tysięcy węzłów
    \item Duża przepustowość - możliwość osiągnięcia przepustowości rzędu terabitów na sekundę
    \item Spójność pamięci podręcznej - gwarancja spójności danych między wszystkimi klientami
    \item Odporność na awarie - możliwość pracy mimo awarii pojedynczych komponentów
    \item Wsparcie dla wielu protokołów dostępu - POSIX, MPI-IO, HDFS
\end{itemize}

W projekcie KubeFold Lustre jest kluczowym komponentem do przechowywania baz danych białkowych.
Jego architektura zapewnia wysoką przepustowość i małe opóźnienia przy dostępie do danych.
System pozwala na jednoczesny dostęp do plików z wielu węzłów klastra wykonujących obliczenia.
Dzięki temu możliwe jest równoległe przetwarzanie danych przez wiele instancji algorytmu AlphaFold.

Lustre znajduje szerokie zastosowanie w centrach obliczeniowych na całym świecie.
Jest wykorzystywany między innymi w superkomputerach z listy TOP500.
System sprawdza się szczególnie w obliczeniach naukowych, gdzie wymagane jest przetwarzanie ogromnych zbiorów danych.
Przykłady zastosowań obejmują symulacje fizyczne, modelowanie klimatu oraz obliczenia genomiczne.

\subsection{Magazyn obiektów Amazon S3}

Amazon Simple Storage Service (S3) to usługa magazynowania obiektów w chmurze.
Zapewnia praktycznie nieograniczoną przestrzeń dyskową z gwarantowaną dostępnością na poziomie 99,999999999\%.
Jest to standard branżowy w zakresie przechowywania danych w chmurze.

Podstawową jednostką organizacyjną w S3 są wiadra (z ang. \textit{buckets}). Każde wiadro ma unikalną nazwę w skali globalnej i może przechowywać dowolną liczbę obiektów.
Obiekty są identyfikowane przez klucze, które mogą zawierać znaki ukośnika do tworzenia struktury hierarchicznej.

S3 stał się standardem \textit{de facto} dla przechowywania danych w aplikacjach chmurowych.
Większość nowoczesnych rozwiązań chmurowych zapewnia integrację z tym systemem.
Dostawcy narzędzi często implementują wsparcie dla S3 jako pierwszy wybór przy integracjach z magazynami danych.

Usługa udostępnia interfejs REST API oraz biblioteki dla wielu języków programowania.
Uwierzytelnianie wykorzystuje podpisy cyfrowe lub tymczasowe poświadczenia.
Kontrola dostępu opiera się na politykach IAM oraz listach ACL. Te standardowe mechanizmy są szeroko wykorzystywane w ekosystemie chmurowym.

S3 zapewnia pełną integrację z innymi usługami AWS. Jest powszechnie używany jako magazyn dla kopii zapasowych, miejsce przechowywania artefaktów czy docelowa lokalizacja dla wyników obliczeń.
Jego niezawodność i skalowalność sprawiają, że jest podstawowym wyborem dla aplikacji wymagających trwałego przechowywania danych.

\subsection{Usługa AWS End User Messaging}


\section{Koncepcja operatora klastra}

\subsection{Architektura operatora klastra}

\subsection{Język programowania Go}